<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Evolving Code at Test Time ‚Äî Building a Mini AlphaEvolve on My Laptop | Dr. Salvador Salazar </title> <meta name="author" content="Dr. Salvador Salazar"> <meta name="description" content="Exploring how LLMs can write, test, and evolve code to solve problems, inspired by DeepMind's AlphaEvolve but built on a laptop."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%9B%B8&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ssalb.github.io/blog/2025/mini-evolve/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper@11.0.5/swiper-bundle.min.css" integrity="sha256-yUoNxsvX+Vo8Trj3lZ/Y5ZBf8HlBFsB6Xwm7rH75/9E=" crossorigin="anonymous"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Dr. Salvador</span> Salazar </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Evolving Code at Test Time ‚Äî Building a Mini AlphaEvolve on My Laptop</h1> <p class="post-meta"> Created in November 18, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a> ¬† ¬∑ ¬† <a href="/blog/tag/agents"> <i class="fa-solid fa-hashtag fa-sm"></i> agents</a> ¬† <a href="/blog/tag/evolutionary-algorithms"> <i class="fa-solid fa-hashtag fa-sm"></i> evolutionary-algorithms</a> ¬† <a href="/blog/tag/llms"> <i class="fa-solid fa-hashtag fa-sm"></i> llms</a> ¬† <a href="/blog/tag/test-time-compute"> <i class="fa-solid fa-hashtag fa-sm"></i> test-time-compute</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Most AI systems work like a vending machine: you put in a prompt, and you get a single, immediate answer. But as I explored in a <a href="/blog/2025/test-time-compute-story-generation/">previous post on story generation</a>, some of the most exciting progress in AI is happening when we let models ‚Äúthink longer‚Äù about a problem. Instead of one forward pass, they use their inference-time compute to search, iterate, and refine their outputs.</p> <p>DeepMind‚Äôs <a href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf" rel="external nofollow noopener" target="_blank">original AlphaEvolve paper</a> is one of the most ambitious examples of this. It uses an evolutionary approach to discover new, more efficient algorithms from scratch, and its power was recently showcased in a follow-up study on <a href="https://arxiv.org/abs/2511.02864" rel="external nofollow noopener" target="_blank">mathematical discovery (Georgiev et al., 2025)</a>. After reading the original paper, I couldn‚Äôt resist trying to build a <strong>tiny, laptop-scale replica</strong> ü§î ‚Äì a project I‚Äôm calling <em>Mini Evolve</em>.</p> <p>My goal wasn‚Äôt to create a production-ready system, but to get a hands-on feel for the core idea: what happens when you let an LLM write, test, and evolve code, guided only by a single performance score? This post is the story of that experiment, what I learned, and why this pattern of test-time adaptation feels so powerful.</p> <h2 id="an-experiment-in-code-evolution">An Experiment in Code Evolution</h2> <p>The core idea is a simple but powerful feedback loop: an LLM proposes a solution as code, the code is executed, its performance is scored, and that score guides the next generation of solutions.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2025-11-18-mini-evolve/flow-diagram-480.webp 480w,/assets/img/blog/2025-11-18-mini-evolve/flow-diagram-800.webp 800w,/assets/img/blog/2025-11-18-mini-evolve/flow-diagram-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/blog/2025-11-18-mini-evolve/flow-diagram.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>To bring this loop to life, I aimed for a setup that was more robust than a single script but still manageable on my laptop. I landed on a simple, container-based distributed system using an orchestrator-worker pattern.</p> <p>An <strong>orchestrator</strong> process manages the main evolutionary loop, sending out jobs to one or more <strong>workers</strong>‚Äìthis allows the system to scale horizontally. These workers are responsible for prompting the LLM to generate new code. I used Redis as a lightweight job queue and to track the results of each experiment.</p> <p>Another critical piece, however, was safety. When a worker receives a new program from the LLM, it doesn‚Äôt run it directly. Instead, it spins up a new, heavily sandboxed <strong>job container</strong> just for that execution. These containers have no internet or host access and run with strict time and resource limits, which was my way of letting the LLM explore creatively without risking it going rogue üòÖ.</p> <p>Finally, the entire process is guided by a user-defined <strong>scoring function</strong> that takes the output of the code and returns a single number‚Äîhigher is better. This is the only ‚Äúguidance‚Äù the system gets.</p> <p>The process itself is a miniature evolutionary search, running as a continuous flow of jobs. The orchestrator seeds the Redis queue with initial tasks. Workers pick them up, prompt the LLM to generate a new code candidate, and push it into a sandboxed container for testing.</p> <p>As scores for each candidate come back, the orchestrator makes its selection for the next generation. It doesn‚Äôt just pick the top performers; to maintain genetic diversity and avoid getting stuck in a local optimum, it also includes a few suboptimal but diverse candidates with a small probability. It then creates a new batch of ‚Äúevolve‚Äù tasks based on these selected programs, and the system hums along, constantly refining its population of solutions.</p> <h2 id="let-it-build-an-ml-pipeline">Let It Build an ML Pipeline</h2> <p>With the system in place, I needed a test case. I gave it the <code class="language-plaintext highlighter-rouge">20 Newsgroups</code> dataset from scikit-learn and a simple scoring function that returned a weighted sum of the model‚Äôs classification accuracy (80%) and an execution time penalty (20%). Crucially, I didn‚Äôt tell the LLM anything about what models to use, feature engineering, or what a typical ML pipeline looks like. The only thing the LLM could see and modify was the <code class="language-plaintext highlighter-rouge">solve()</code> function, which contained the initial, suboptimal pipeline.</p> <hr> <details><summary>Click to see the full seed script and scoring function</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">scoring_function</span><span class="p">(</span><span class="n">result</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Score based on text classifier accuracy and performance.
    - Trains on a split of scikit-learn</span><span class="sh">'</span><span class="s">s 20 Newsgroups dataset using the `result` trainer.
    - Tests on a held-out set.
    - Combines correctness (accuracy) and speed (train + predict time).
    </span><span class="sh">"""</span>
    <span class="kn">import</span> <span class="n">time</span>
    <span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>
    <span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

    <span class="c1"># Load data (remove headers/footers/quotes to reduce noise)
</span>    <span class="n">data</span> <span class="o">=</span> <span class="nf">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="sh">"</span><span class="s">test</span><span class="sh">"</span><span class="p">,</span> <span class="n">remove</span><span class="o">=</span><span class="p">(</span><span class="sh">"</span><span class="s">headers</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">footers</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">quotes</span><span class="sh">"</span><span class="p">))</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">target</span>

    <span class="c1"># Fixed split for repeatability
</span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span>
    <span class="p">)</span>

    <span class="c1"># Train the model using the provided training function
</span>    <span class="k">try</span><span class="p">:</span>
        <span class="n">start_train</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
        <span class="n">model</span> <span class="o">=</span> <span class="nf">result</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>  <span class="c1"># must return a fitted estimator with .predict
</span>        <span class="n">train_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_train</span>
    <span class="k">except</span> <span class="nb">Exception</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>  <span class="c1"># training failed
</span>
    <span class="c1"># Predict on the test set
</span>    <span class="k">try</span><span class="p">:</span>
        <span class="n">start_pred</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="n">pred_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_pred</span>
    <span class="k">except</span> <span class="nb">Exception</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>  <span class="c1"># prediction failed
</span>
    <span class="c1"># Correctness (accuracy)
</span>    <span class="n">accuracy</span> <span class="o">=</span> <span class="nf">float</span><span class="p">((</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">).</span><span class="nf">mean</span><span class="p">())</span>  <span class="c1"># 0..1
</span>
    <span class="c1"># Performance scoring: encourage quick training and inference
</span>    <span class="n">max_train_time</span> <span class="o">=</span> <span class="mf">10.0</span>   <span class="c1"># seconds
</span>    <span class="n">max_pred_time</span> <span class="o">=</span> <span class="mf">3.0</span>    <span class="c1"># seconds
</span>
    <span class="k">def</span> <span class="nf">time_to_score</span><span class="p">(</span><span class="n">elapsed</span><span class="p">,</span> <span class="n">cap</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">elapsed</span> <span class="o">&lt;=</span> <span class="n">cap</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">1.0</span>
        <span class="c1"># decay scale: every extra cap reduces score by 1.0
</span>        <span class="k">return</span> <span class="nf">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">elapsed</span> <span class="o">-</span> <span class="n">cap</span><span class="p">)</span> <span class="o">/</span> <span class="n">cap</span><span class="p">)</span>

    <span class="n">training_score</span> <span class="o">=</span> <span class="nf">time_to_score</span><span class="p">(</span><span class="n">train_time</span><span class="p">,</span> <span class="n">max_train_time</span><span class="p">)</span>
    <span class="n">prediction_score</span> <span class="o">=</span> <span class="nf">time_to_score</span><span class="p">(</span><span class="n">pred_time</span><span class="p">,</span> <span class="n">max_pred_time</span><span class="p">)</span>
    <span class="n">performance_score</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">training_score</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">prediction_score</span>

    <span class="c1"># Final weighted score: accuracy (80%) + performance (20%)
</span>    <span class="n">final_score</span> <span class="o">=</span> <span class="mf">0.8</span> <span class="o">*</span> <span class="n">accuracy</span> <span class="o">+</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">performance_score</span>
    <span class="k">return</span> <span class="n">final_score</span>


<span class="k">def</span> <span class="nf">solve</span><span class="p">():</span>
    <span class="sh">"""</span><span class="s">
    Return a function that trains and returns a fitted scikit-learn text classifier.
    </span><span class="sh">"""</span>
    <span class="kn">from</span> <span class="n">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
    <span class="kn">from</span> <span class="n">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
    <span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

    <span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">model</span> <span class="o">=</span> <span class="nf">make_pipeline</span><span class="p">(</span>
            <span class="nc">CountVectorizer</span><span class="p">(</span>
                <span class="n">lowercase</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="sh">"</span><span class="s">liblinear</span><span class="sh">"</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model</span>

    <span class="k">return</span> <span class="n">train_model</span>



<span class="n">result</span> <span class="o">=</span> <span class="nf">solve</span><span class="p">()</span>
<span class="n">score</span> <span class="o">=</span> <span class="nf">scoring_function</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">SCORE: </span><span class="si">{</span><span class="n">score</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> </details> <hr> <p>Over several generations, something fascinating happened ‚ú®. The system started discovering better approaches on its own, first by <em>more obvious</em> changes, but later adding more nuanced elements. It swapped <code class="language-plaintext highlighter-rouge">CountVectorizer</code> for <code class="language-plaintext highlighter-rouge">TfidfVectorizer</code>, added <code class="language-plaintext highlighter-rouge">stop_words</code>, and even found useful parameters like <code class="language-plaintext highlighter-rouge">sublinear_tf</code>. It eventually settled on a much more refined pipeline:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="nf">make_pipeline</span><span class="p">(</span>
    <span class="nc">TfidfVectorizer</span><span class="p">(</span>
        <span class="n">lowercase</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">stop_words</span><span class="o">=</span><span class="sh">'</span><span class="s">english</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">norm</span><span class="o">=</span><span class="sh">'</span><span class="s">l2</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">smooth_idf</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">use_idf</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">sublinear_tf</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">),</span>
    <span class="nc">SelectKBest</span><span class="p">(</span><span class="n">chi2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">8000</span><span class="p">),</span>
    <span class="nc">SGDClassifier</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2025-11-18-mini-evolve/best-score-evolution-480.webp 480w,/assets/img/blog/2025-11-18-mini-evolve/best-score-evolution-800.webp 800w,/assets/img/blog/2025-11-18-mini-evolve/best-score-evolution-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/blog/2025-11-18-mini-evolve/best-score-evolution.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The learning curve of the experiment. This chart plots the classification accuracy of the top-ranked solution from each generation (#1 is best). While solutions were ranked using a combined score (accuracy and performance), the accuracy component showed clear, steady improvement, confirming the system was effectively evolving better models. </div> <h2 id="why-this-matters-even-at-a-small-scale">Why This Matters (Even at a Small Scale)</h2> <p>This little experiment reinforced just how powerful the ‚Äúsearch-at-inference-time‚Äù paradigm is. It‚Äôs not about finding the world‚Äôs best classifier, it‚Äôs about what this pattern represents.</p> <ul> <li> <strong>Adaptation is the Killer App:</strong> The model adapted its solution to the specific problem <em>while solving it</em>. It didn‚Äôt rely on pre-trained knowledge alone; it used feedback to discover what actually worked.</li> <li> <strong>Beyond Bigger Models:</strong> This approach offers a path to better results that isn‚Äôt just ‚Äútrain a bigger model.‚Äù It‚Äôs about using compute more intelligently at inference time.</li> <li> <strong>Grounded in Reality:</strong> By executing code and getting real feedback, the LLM is forced to generate solutions that work in practice, not just ones that look plausible as text. The score doesn‚Äôt lie üòâ.</li> </ul> <p>Ultimately, <em>Mini Evolve</em> is a glimpse into a design space where we don‚Äôt just prompt models for answers. Instead, we give them goals and let them build, test, and discover their own solutions.</p> <h2 id="whats-next">What‚Äôs Next?</h2> <p>While this was a side project I‚Äôve been building in my free time, it has definitely sparked more questions than answers (as usual üòÖ). I‚Äôm not planning to open-source the code just yet, as many parts still need to be made more configurable. For instance, the prompts that guide the LLM‚Äôs mutations are currently hard-coded Python strings, and generalizing them is a project in itself! üòÇ</p> <p>If there‚Äôs interest, I might write a follow-up post diving into some of these internal mechanics.</p> <p>But what I‚Äôm most curious about is what <em>you</em> would do with a system like this. I‚Äôd love to hear from readers, especially those with domain expertise in fields outside of machine learning. What‚Äôs a tricky optimization problem in your area‚Äîbe it in logistics, biology, or finance‚Äîthat you think would be a fun challenge for an evolutionary code-writer? <strong>Let me know your ideas!</strong> If you want to connect, you can find links to my GitHub and LinkedIn profiles on my <a href="https://ssalb.github.io/">home page</a>.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/auto-rag-agent/">From Docs to Answers: My Smolagents + Docling + DuckDB Experiment ü§ñ</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/cgan-class-balancer/">A Conditional GAN for Data Augmentation: A Cautionary Tale</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/test-time-compute-story-generation/">Test-Time Compute: My Take on Story Generation</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/company-no-ml/">If your company is not doing ML, it (probably) won‚Äôt start any time soon either</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Dr. Salvador Salazar. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/swiper@11.0.5/swiper-element-bundle.min.js" integrity="sha256-BPrwikijIybg9OQC5SYFFqhBjERYOn97tCureFgYH1E=" crossorigin="anonymous"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>