<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://ssalb.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ssalb.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-11-18T14:00:13+00:00</updated><id>https://ssalb.github.io/feed.xml</id><title type="html">blank</title><subtitle></subtitle><entry><title type="html">Evolving Code at Test Time ‚Äî Building a Mini AlphaEvolve on My Laptop</title><link href="https://ssalb.github.io/blog/2025/mini-evolve/" rel="alternate" type="text/html" title="Evolving Code at Test Time ‚Äî Building a Mini AlphaEvolve on My Laptop"/><published>2025-11-18T09:00:00+00:00</published><updated>2025-11-18T09:00:00+00:00</updated><id>https://ssalb.github.io/blog/2025/mini-evolve</id><content type="html" xml:base="https://ssalb.github.io/blog/2025/mini-evolve/"><![CDATA[<p>Most AI systems work like a vending machine: you put in a prompt, and you get a single, immediate answer. But as I explored in a <a href="/blog/2025/test-time-compute-story-generation/">previous post on story generation</a>, some of the most exciting progress in AI is happening when we let models ‚Äúthink longer‚Äù about a problem. Instead of one forward pass, they use their inference-time compute to search, iterate, and refine their outputs.</p> <p>DeepMind‚Äôs <a href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf">original AlphaEvolve paper</a> is one of the most ambitious examples of this. It uses an evolutionary approach to discover new, more efficient algorithms from scratch, and its power was recently showcased in a follow-up study on <a href="https://arxiv.org/abs/2511.02864">mathematical discovery (Georgiev et al., 2025)</a>. After reading the original paper, I couldn‚Äôt resist trying to build a <strong>tiny, laptop-scale replica</strong> ü§î ‚Äì a project I‚Äôm calling <em>Mini Evolve</em>.</p> <p>My goal wasn‚Äôt to create a production-ready system, but to get a hands-on feel for the core idea: what happens when you let an LLM write, test, and evolve code, guided only by a single performance score? This post is the story of that experiment, what I learned, and why this pattern of test-time adaptation feels so powerful.</p> <h2 id="an-experiment-in-code-evolution">An Experiment in Code Evolution</h2> <p>The core idea is a simple but powerful feedback loop: an LLM proposes a solution as code, the code is executed, its performance is scored, and that score guides the next generation of solutions.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2025-11-18-mini-evolve/flow-diagram-480.webp 480w,/assets/img/blog/2025-11-18-mini-evolve/flow-diagram-800.webp 800w,/assets/img/blog/2025-11-18-mini-evolve/flow-diagram-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/2025-11-18-mini-evolve/flow-diagram.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>To bring this loop to life, I aimed for a setup that was more robust than a single script but still manageable on my laptop. I landed on a simple, container-based distributed system using an orchestrator-worker pattern.</p> <p>An <strong>orchestrator</strong> process manages the main evolutionary loop, sending out jobs to one or more <strong>workers</strong>‚Äìthis allows the system to scale horizontally. These workers are responsible for prompting the LLM to generate new code. I used Redis as a lightweight job queue and to track the results of each experiment.</p> <p>Another critical piece, however, was safety. When a worker receives a new program from the LLM, it doesn‚Äôt run it directly. Instead, it spins up a new, heavily sandboxed <strong>job container</strong> just for that execution. These containers have no internet or host access and run with strict time and resource limits, which was my way of letting the LLM explore creatively without risking it going rogue üòÖ.</p> <p>Finally, the entire process is guided by a user-defined <strong>scoring function</strong> that takes the output of the code and returns a single number‚Äîhigher is better. This is the only ‚Äúguidance‚Äù the system gets.</p> <p>The process itself is a miniature evolutionary search, running as a continuous flow of jobs. The orchestrator seeds the Redis queue with initial tasks. Workers pick them up, prompt the LLM to generate a new code candidate, and push it into a sandboxed container for testing.</p> <p>As scores for each candidate come back, the orchestrator makes its selection for the next generation. It doesn‚Äôt just pick the top performers; to maintain genetic diversity and avoid getting stuck in a local optimum, it also includes a few suboptimal but diverse candidates with a small probability. It then creates a new batch of ‚Äúevolve‚Äù tasks based on these selected programs, and the system hums along, constantly refining its population of solutions.</p> <h2 id="let-it-build-an-ml-pipeline">Let It Build an ML Pipeline</h2> <p>With the system in place, I needed a test case. I gave it the <code class="language-plaintext highlighter-rouge">20 Newsgroups</code> dataset from scikit-learn and a simple scoring function that returned a weighted sum of the model‚Äôs classification accuracy (80%) and an execution time penalty (20%). Crucially, I didn‚Äôt tell the LLM anything about what models to use, feature engineering, or what a typical ML pipeline looks like. The only thing the LLM could see and modify was the <code class="language-plaintext highlighter-rouge">solve()</code> function, which contained the initial, suboptimal pipeline.</p> <hr/> <details><summary>Click to see the full seed script and scoring function</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">scoring_function</span><span class="p">(</span><span class="n">result</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Score based on text classifier accuracy and performance.
    - Trains on a split of scikit-learn</span><span class="sh">'</span><span class="s">s 20 Newsgroups dataset using the `result` trainer.
    - Tests on a held-out set.
    - Combines correctness (accuracy) and speed (train + predict time).
    </span><span class="sh">"""</span>
    <span class="kn">import</span> <span class="n">time</span>
    <span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>
    <span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

    <span class="c1"># Load data (remove headers/footers/quotes to reduce noise)
</span>    <span class="n">data</span> <span class="o">=</span> <span class="nf">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="sh">"</span><span class="s">test</span><span class="sh">"</span><span class="p">,</span> <span class="n">remove</span><span class="o">=</span><span class="p">(</span><span class="sh">"</span><span class="s">headers</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">footers</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">quotes</span><span class="sh">"</span><span class="p">))</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">target</span>

    <span class="c1"># Fixed split for repeatability
</span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span>
    <span class="p">)</span>

    <span class="c1"># Train the model using the provided training function
</span>    <span class="k">try</span><span class="p">:</span>
        <span class="n">start_train</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
        <span class="n">model</span> <span class="o">=</span> <span class="nf">result</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>  <span class="c1"># must return a fitted estimator with .predict
</span>        <span class="n">train_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_train</span>
    <span class="k">except</span> <span class="nb">Exception</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>  <span class="c1"># training failed
</span>
    <span class="c1"># Predict on the test set
</span>    <span class="k">try</span><span class="p">:</span>
        <span class="n">start_pred</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="n">pred_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_pred</span>
    <span class="k">except</span> <span class="nb">Exception</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>  <span class="c1"># prediction failed
</span>
    <span class="c1"># Correctness (accuracy)
</span>    <span class="n">accuracy</span> <span class="o">=</span> <span class="nf">float</span><span class="p">((</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">).</span><span class="nf">mean</span><span class="p">())</span>  <span class="c1"># 0..1
</span>
    <span class="c1"># Performance scoring: encourage quick training and inference
</span>    <span class="n">max_train_time</span> <span class="o">=</span> <span class="mf">10.0</span>   <span class="c1"># seconds
</span>    <span class="n">max_pred_time</span> <span class="o">=</span> <span class="mf">3.0</span>    <span class="c1"># seconds
</span>
    <span class="k">def</span> <span class="nf">time_to_score</span><span class="p">(</span><span class="n">elapsed</span><span class="p">,</span> <span class="n">cap</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">elapsed</span> <span class="o">&lt;=</span> <span class="n">cap</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">1.0</span>
        <span class="c1"># decay scale: every extra cap reduces score by 1.0
</span>        <span class="k">return</span> <span class="nf">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span><span class="n">elapsed</span> <span class="o">-</span> <span class="n">cap</span><span class="p">)</span> <span class="o">/</span> <span class="n">cap</span><span class="p">)</span>

    <span class="n">training_score</span> <span class="o">=</span> <span class="nf">time_to_score</span><span class="p">(</span><span class="n">train_time</span><span class="p">,</span> <span class="n">max_train_time</span><span class="p">)</span>
    <span class="n">prediction_score</span> <span class="o">=</span> <span class="nf">time_to_score</span><span class="p">(</span><span class="n">pred_time</span><span class="p">,</span> <span class="n">max_pred_time</span><span class="p">)</span>
    <span class="n">performance_score</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">training_score</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">prediction_score</span>

    <span class="c1"># Final weighted score: accuracy (80%) + performance (20%)
</span>    <span class="n">final_score</span> <span class="o">=</span> <span class="mf">0.8</span> <span class="o">*</span> <span class="n">accuracy</span> <span class="o">+</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">performance_score</span>
    <span class="k">return</span> <span class="n">final_score</span>


<span class="k">def</span> <span class="nf">solve</span><span class="p">():</span>
    <span class="sh">"""</span><span class="s">
    Return a function that trains and returns a fitted scikit-learn text classifier.
    </span><span class="sh">"""</span>
    <span class="kn">from</span> <span class="n">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
    <span class="kn">from</span> <span class="n">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
    <span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

    <span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">model</span> <span class="o">=</span> <span class="nf">make_pipeline</span><span class="p">(</span>
            <span class="nc">CountVectorizer</span><span class="p">(</span>
                <span class="n">lowercase</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="sh">"</span><span class="s">liblinear</span><span class="sh">"</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model</span>

    <span class="k">return</span> <span class="n">train_model</span>



<span class="n">result</span> <span class="o">=</span> <span class="nf">solve</span><span class="p">()</span>
<span class="n">score</span> <span class="o">=</span> <span class="nf">scoring_function</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">SCORE: </span><span class="si">{</span><span class="n">score</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> </details> <hr/> <p>Over several generations, something fascinating happened ‚ú®. The system started discovering better approaches on its own, first by <em>more obvious</em> changes, but later adding more nuanced elements. It swapped <code class="language-plaintext highlighter-rouge">CountVectorizer</code> for <code class="language-plaintext highlighter-rouge">TfidfVectorizer</code>, added <code class="language-plaintext highlighter-rouge">stop_words</code>, and even found useful parameters like <code class="language-plaintext highlighter-rouge">sublinear_tf</code>. It eventually settled on a much more refined pipeline:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="nf">make_pipeline</span><span class="p">(</span>
    <span class="nc">TfidfVectorizer</span><span class="p">(</span>
        <span class="n">lowercase</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">stop_words</span><span class="o">=</span><span class="sh">'</span><span class="s">english</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">norm</span><span class="o">=</span><span class="sh">'</span><span class="s">l2</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">smooth_idf</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">use_idf</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">sublinear_tf</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">),</span>
    <span class="nc">SelectKBest</span><span class="p">(</span><span class="n">chi2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">8000</span><span class="p">),</span>
    <span class="nc">SGDClassifier</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2025-11-18-mini-evolve/best-score-evolution-480.webp 480w,/assets/img/blog/2025-11-18-mini-evolve/best-score-evolution-800.webp 800w,/assets/img/blog/2025-11-18-mini-evolve/best-score-evolution-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/2025-11-18-mini-evolve/best-score-evolution.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The learning curve of the experiment. This chart plots the classification accuracy of the top-ranked solution from each generation (#1 is best). While solutions were ranked using a combined score (accuracy and performance), the accuracy component showed clear, steady improvement, confirming the system was effectively evolving better models. </div> <h2 id="why-this-matters-even-at-a-small-scale">Why This Matters (Even at a Small Scale)</h2> <p>This little experiment reinforced just how powerful the ‚Äúsearch-at-inference-time‚Äù paradigm is. It‚Äôs not about finding the world‚Äôs best classifier, it‚Äôs about what this pattern represents.</p> <ul> <li><strong>Adaptation is the Killer App:</strong> The model adapted its solution to the specific problem <em>while solving it</em>. It didn‚Äôt rely on pre-trained knowledge alone; it used feedback to discover what actually worked.</li> <li><strong>Beyond Bigger Models:</strong> This approach offers a path to better results that isn‚Äôt just ‚Äútrain a bigger model.‚Äù It‚Äôs about using compute more intelligently at inference time.</li> <li><strong>Grounded in Reality:</strong> By executing code and getting real feedback, the LLM is forced to generate solutions that work in practice, not just ones that look plausible as text. The score doesn‚Äôt lie üòâ.</li> </ul> <p>Ultimately, <em>Mini Evolve</em> is a glimpse into a design space where we don‚Äôt just prompt models for answers. Instead, we give them goals and let them build, test, and discover their own solutions.</p> <h2 id="whats-next">What‚Äôs Next?</h2> <p>While this was a side project I‚Äôve been building in my free time, it has definitely sparked more questions than answers (as usual üòÖ). I‚Äôm not planning to open-source the code just yet, as many parts still need to be made more configurable. For instance, the prompts that guide the LLM‚Äôs mutations are currently hard-coded Python strings, and generalizing them is a project in itself! üòÇ</p> <p>If there‚Äôs interest, I might write a follow-up post diving into some of these internal mechanics.</p> <p>But what I‚Äôm most curious about is what <em>you</em> would do with a system like this. I‚Äôd love to hear from readers, especially those with domain expertise in fields outside of machine learning. What‚Äôs a tricky optimization problem in your area‚Äîbe it in logistics, biology, or finance‚Äîthat you think would be a fun challenge for an evolutionary code-writer? <strong>Let me know your ideas!</strong> If you want to connect, you can find links to my GitHub and LinkedIn profiles on my <a href="https://ssalb.github.io/">home page</a>.</p>]]></content><author><name></name></author><category term="agents"/><category term="evolutionary-algorithms"/><category term="llms"/><category term="test-time-compute"/><summary type="html"><![CDATA[Exploring how LLMs can write, test, and evolve code to solve problems, inspired by DeepMind's AlphaEvolve but built on a laptop.]]></summary></entry><entry><title type="html">From Docs to Answers: My Smolagents + Docling + DuckDB Experiment ü§ñ</title><link href="https://ssalb.github.io/blog/2025/auto-rag-agent/" rel="alternate" type="text/html" title="From Docs to Answers: My Smolagents + Docling + DuckDB Experiment ü§ñ"/><published>2025-06-25T09:00:00+00:00</published><updated>2025-06-25T09:00:00+00:00</updated><id>https://ssalb.github.io/blog/2025/auto-rag-agent</id><content type="html" xml:base="https://ssalb.github.io/blog/2025/auto-rag-agent/"><![CDATA[<p>To the surprise of no one, <strong>retrieval-augmented generation (RAG)</strong> and <strong>agents</strong> have been the biggest buzz in the AI world for over a year now. Today, you can choose from loads of libraries, vector databases, models, and frameworks to build your own applications, and more keep popping up all the time!</p> <p>Among the multitude of options, three particular new contenders caught my eye:</p> <ul> <li>Hugging Face‚Äôs <a href="https://github.com/huggingface/smolagents">smolagents</a>, especially their <em>code agent</em> (more on that later).</li> <li><a href="https://duckdb.org/">DuckDB</a>, which‚Äîat the risk of underselling it‚ÄîI will be using it as an <em>OLAP SQLite</em>. It‚Äôs recently added support for a vector data type and similarity search, making it very interesting for this kind of project.</li> <li>IBM‚Äôs <a href="https://docling-project.github.io/docling/">Docling</a>‚Äîa simple, flexible, and powerful document processor/parser.</li> </ul> <p>So there I was, curious about a lightweight, in-process vector DB, a promising document parser, and a new agents framework‚Ä¶ what could I possibly do with them? ü§î <strong>An agent that ingests documents and <em>RAGs</em> for you</strong> üí°</p> <p>This article shares my first experience and impressions while building a <em>smol</em> prototype agent that ingests your documents, indexes them for retrieval, and answers questions about their content.</p> <p>Do you want to see the code? <a href="https://github.com/ssalb/auto-rag-agent">Here‚Äôs the repo</a> too!</p> <h2 id="the-stack">The Stack</h2> <p>This project uses several well-known packages‚Äîincluding <em>transformers</em> and <em>sentence-transformers</em> for LLMs and embeddings, plus <em>Gradio</em> for the UI. I won‚Äôt detail all of them here, but I want to highlight our three main players.</p> <h4 id="smolagents">Smolagents</h4> <p>Smolagents is a minimalist AI agent framework from Hugging Face. As far as I know (and I don‚Äôt follow every framework), they were the first to push the idea of a <em>code agent</em> in an open‚Äësource setting. Instead of interacting with tools via JSON, the code agent writes Python code that executes tools inside a sandbox. That makes it both more flexible and more efficient, since it can tackle complex workflows in fewer steps. For example, it could execute something like the following in a single step:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">result_1</span> <span class="o">=</span> <span class="nf">tool_1</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="k">if</span> <span class="n">result_1</span><span class="p">:</span>
    <span class="n">result_2</span> <span class="o">=</span> <span class="nf">tool_2</span><span class="p">(</span><span class="n">result_1</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">result_2</span><span class="p">)</span>
</code></pre></div></div> <p>Like most HF projects, it‚Äôs model‚Äëagnostic‚Äîyou can plug in your favorite LLM (open‚Äësource or API‚Äëbased) and it integrates seamlessly with the <em>transformers</em> library.</p> <p>At the time of writing, they‚Äôve also added Vision‚ÄìLanguage models (VLMs) and <em>Computer Use</em> support in the last few weeks, opening up even more possibilities üöÄ</p> <h4 id="docling">Docling</h4> <p>I don‚Äôt think Docling has received the hype it deserves. IBM open‚Äësourced it a while back, yet I haven‚Äôt seen many people talking about it. Out of the box, it takes tons of document formats and parses them into JSON or Markdown. What used to require multiple libraries and custom parsers is now a one‚Äëstop shop. It‚Äôs so straightforward that I barely had to tweak anything üòÖ‚Äîwhich says a lot about its defaults.</p> <p>You can also supercharge it with VLMs, though I found the out‚Äëof‚Äëthe‚Äëbox pipeline already covers the ‚Äú80%‚Äù of most RAG needs.</p> <h4 id="duckdb">DuckDB</h4> <p>DuckDB delivered exactly what it promised: an in‚Äëprocess OLAP database‚Äîthink ‚ÄúSQLite for analytics‚Äù‚Äîand it recently added experimental support for fixed‚Äësize arrays and vector similarity search. That means you can store embeddings directly in a column and run nearest‚Äëneighbor queries with plain SQL.</p> <p>With the <code class="language-plaintext highlighter-rouge">vss</code> extension, building an <code class="language-plaintext highlighter-rouge">HNSW</code> index and performing similarity search takes just a few lines. No servers, no extra services, just a local file and your queries. For this prototype, that meant everything stayed self‚Äëcontained: ingest, embed, store, and search. Super convenient.</p> <h2 id="building-the-rag-agent">Building the RAG Agent</h2> <p>The core idea is simple:</p> <ul> <li>A chat UI built on Gradio</li> <li>A code agent following the <a href="https://www.ibm.com/think/topics/react-agent">ReAct framework</a></li> <li> <p>Two initial tools:</p> <ol> <li><strong>Indexer</strong>: ingests, parses, and indexes documents</li> <li><strong>Retriever</strong>: embeds queries and performs similarity search</li> </ol> </li> </ul> <p>During a conversation, the user can ask the agent to index new documents‚Äîeither by upload or URL‚Äîor to answer questions about any indexed content.</p> <p>In practice (no surprise to anyone building agents), it didn‚Äôt work perfectly at first. For this reason I ended up adding a third tool:</p> <ol> <li><strong>Summarizer</strong>: condenses one or more text chunks, either generally or tailored to a query.</li> </ol> <p>All tools are invoked via generated Python code. The same LLM powers both the agent‚Äôs reasoning and the summarization, keeping the architecture simple.</p> <h3 id="indexing">Indexing</h3> <p>For each document, the indexer:</p> <ol> <li><strong>Parses</strong> the file with Docling</li> <li><strong>Extracts named entities</strong> via an NER‚Äëtuned model</li> <li><strong>Computes</strong> an embedding vector</li> <li> <p><strong>Inserts</strong> a row per chunk into DuckDB, storing:</p> <ul> <li>Document name</li> <li>Chunk text</li> <li>Named entities</li> <li>Embedding vector</li> </ul> </li> </ol> <h3 id="retrieval">Retrieval</h3> <p>The retriever:</p> <ol> <li><strong>Extracts named entities</strong> from the query</li> <li><strong>Embeds</strong> the query</li> <li><strong>Retrieves</strong> chunks via similarity search (optionally filtered by document name)</li> <li><strong>Reranks</strong> based on shared named entities between chunk and query</li> </ol> <p>This quick entity‚Äëbased reranking boosted relevance without requiring expensive cross‚Äëencoders or reranker models. It‚Äôs not perfect, but it‚Äôs surprisingly effective. An obvious but much more intricate extension to this approach would be to build a knowledge graph using these names entities.</p> <h2 id="observations--takeaways">Observations &amp; Takeaways</h2> <p>While I hinted at a few challenges above, the overall experience with these tools has been very positive. Here are my main takeaways:</p> <swiper-container keyboard="true" navigation="true" pagination="true" pagination-clickable="true" pagination-dynamic-bullets="true" rewind="true"> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2025-06-25-auto-rag/slider-1-480.webp 480w,/assets/img/blog/2025-06-25-auto-rag/slider-1-800.webp 800w,/assets/img/blog/2025-06-25-auto-rag/slider-1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/2025-06-25-auto-rag/slider-1.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2025-06-25-auto-rag/slider-2-480.webp 480w,/assets/img/blog/2025-06-25-auto-rag/slider-2-800.webp 800w,/assets/img/blog/2025-06-25-auto-rag/slider-2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/2025-06-25-auto-rag/slider-2.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2025-06-25-auto-rag/slider-3-480.webp 480w,/assets/img/blog/2025-06-25-auto-rag/slider-3-800.webp 800w,/assets/img/blog/2025-06-25-auto-rag/slider-3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/2025-06-25-auto-rag/slider-3.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2025-06-25-auto-rag/slider-4-480.webp 480w,/assets/img/blog/2025-06-25-auto-rag/slider-4-800.webp 800w,/assets/img/blog/2025-06-25-auto-rag/slider-4-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/2025-06-25-auto-rag/slider-4.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> </swiper-container> <h4 id="agent-bias-toward-tool-usage">Agent bias toward tool usage</h4> <p>By default, the code agent strongly prefers using tools‚Äîeven inventing them‚Äîinstead of solving tasks directly as an LLM. To work around this, you can tweak the system prompt or add deliberately goofy tools. I opted for the latter, introducing the <strong>summarizer</strong>. This played to the agent‚Äôs tool‚Äëcentric tendencies while leveraging the LLM‚Äôs strengths in summarization.</p> <h4 id="model-size-matters">Model size matters</h4> <p>Earlier this year, I wrote about <a href="https://ssalb.github.io/blog/2025/test-time-compute-story-generation/">test‚Äëtime compute</a> and how smaller LLMs can outperform expectations. In this case, though, model size really did matter. Models in the ~7B‚Äì11B range struggled with open‚Äëended tasks, needing explicit instructions to use specific tools. Swapping up to ~30B‚Äì70B turned that around: the larger models handled ambiguous requests and self‚Äëcorrected much better. The trade‚Äëoff was losing local inferencing and moving to cloud endpoints.</p> <h4 id="final-verdict">Final verdict</h4> <p>All in all, I came away with a positive impression of the three tools that motivated this project. Docling is incredibly simple yet powerful ‚ÄîI‚Äôll definitely reach for it again when processing documents. DuckDB is great, but I see its real potential more as a Delta Lake alternative than for simple, local storage (see their <a href="https://duckdb.org/2025/05/27/ducklake.html">Duck Lake post</a>). And smolagents? I‚Äôm excited to take it beyond this PoC, especially if async support is added. It‚Äôs shaping up to be a solid production contender.</p>]]></content><author><name></name></author><category term="agents"/><category term="RAG"/><category term="llms"/><category term="transformers"/><summary type="html"><![CDATA[Testing smolagents, docling, and duckdb through an agent that RAGs for you.]]></summary></entry><entry><title type="html">A Conditional GAN for Data Augmentation: A Cautionary Tale</title><link href="https://ssalb.github.io/blog/2025/cgan-class-balancer/" rel="alternate" type="text/html" title="A Conditional GAN for Data Augmentation: A Cautionary Tale"/><published>2025-02-23T09:00:00+00:00</published><updated>2025-02-23T09:00:00+00:00</updated><id>https://ssalb.github.io/blog/2025/cgan-class-balancer</id><content type="html" xml:base="https://ssalb.github.io/blog/2025/cgan-class-balancer/"><![CDATA[<p>In recent years, the use of synthetic data has become increasingly important for improving machine learning models, especially in situations where data is scarce, sensitive, or simply when it becomes impractical to keep scaling real-world data. Major tech companies like <a href="https://www.businessinsider.com/ai-synthetic-data-industry-debate-over-fake-2024-8">Google, OpenAI</a>, and particularly Nvidia with the release of <a href="https://blogs.nvidia.com/blog/nemotron-4-synthetic-data-generation-llm-training/">Nemotron</a> and their <a href="https://nvidianews.nvidia.com/news/nvidia-expands-omniverse-with-generative-physical-ai">Omniverse platform</a>, among others, have been investing heavily in this. It is also an active research area in academia, with <a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Stanford‚Äôs Alpaca</a> probably being the first recent example that comes to mind for most people in the field.</p> <p>This is the backdrop for this project, where I set out to answer the following question:</p> <p><strong>For an image classification task, can generated images improve model performance on an imbalanced dataset?</strong></p> <p>In other words, does rebalancing an imbalanced dataset by sampling synthetic images for minority classes improve classification accuracy‚Äîall while staying on a private, consumer-grade budget (because I‚Äôm not a research lab üòú)?</p> <p>To this end, I used an unbalanced version of the EuroSAT dataset, trained a conditional GAN to generate new synthetic samples conditioned on a given class, and fine-tuned a pre-trained <em>EfficientNetB2</em> on different versions of this dataset. I trained all models on a rather modest instance from AWS SageMaker, while some other tasks were run on my personal PC. If you‚Äôre interested, the code and scripts are all available under <a href="https://github.com/ssalb/cgan-class-balancer">this GitHub repo</a>.</p> <p><em>Spoiler alert: not everything went as planned, but those unexpected twists made the journey all the more interesting!</em></p> <hr/> <h2 id="dataset-overview">Dataset Overview</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2025-02-23-cgan-class/example_images-480.webp 480w,/assets/img/blog/2025-02-23-cgan-class/example_images-800.webp 800w,/assets/img/blog/2025-02-23-cgan-class/example_images-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/2025-02-23-cgan-class/example_images.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Examples from the EuroSAT dataset. Not every class is displayed. </div> <p><a href="https://github.com/phelber/EuroSAT">EuroSAT</a> consists of 10 classes of land-use/land-cover from ESA‚Äôs Sentinel-2 satellite images <a href="https://arxiv.org/abs/1709.00029">(Helber et al., 2019)</a>, with 27,000+ total images (RGB or multispectral). Classes include:</p> <ul> <li>Annual Crop</li> <li>Forest</li> <li>Herbaceous Vegetation</li> <li>Highway</li> <li>Industrial Buildings</li> <li>Pasture</li> <li>Permanent Crop</li> <li>Residential Buildings</li> <li>River</li> <li>SeaLake</li> </ul> <p>In particular I‚Äôve used <a href="https://huggingface.co/datasets/blanchon/EuroSAT_RGB">this version</a> from Hugging Face‚Äôs Datasets, which only contains the RGB images and already comes with a train-validation-test split.</p> <p>The original dataset is well balanced, so I artificially reduced two classes‚Äì<em>Highway</em> and <em>River</em>‚Äìby 85% in the training set, leaving the validation and test sets untouched. I picked these two becuase they show quite distinct features, unlilke, say, <em>Forest</em> or <em>SeaLake</em>, wich can often be very flat, but they‚Äôre also not as complex as <em>Industrial Buildings</em> or <em>Residential Buildings</em> can be.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2025-02-23-cgan-class/eurosat_training_distr-480.webp 480w,/assets/img/blog/2025-02-23-cgan-class/eurosat_training_distr-800.webp 800w,/assets/img/blog/2025-02-23-cgan-class/eurosat_training_distr-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/2025-02-23-cgan-class/eurosat_training_distr.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2025-02-23-cgan-class/eurosat_unbalanced_distr-480.webp 480w,/assets/img/blog/2025-02-23-cgan-class/eurosat_unbalanced_distr-800.webp 800w,/assets/img/blog/2025-02-23-cgan-class/eurosat_unbalanced_distr-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/2025-02-23-cgan-class/eurosat_unbalanced_distr.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The class counts of the original training set (left) and the atrificially unbalanced one (right) with the classes <i>Highway</i> and <i>River</i> undersampled by 85% </div> <h2 id="experiment-design">Experiment Design</h2> <p>Throughout this experiment, I‚Äôve used the <a href="https://keras.io/about/">Keras 3</a> framework with TensorFlow as the backend. I‚Äôve tried to keep my code as ‚Äúbackend agnostic‚Äù as possible, and most models should actually work with other supported backends (currently PyTorch and JAX). The only exception should be the custom training loop for the GAN. If you‚Äôre interested in optimizers and hyperparameters, check out the code.</p> <p>Here‚Äôs the plan:</p> <h4 id="baseline">Baseline</h4> <p>Fine-tune a pretrained <em>EfficientNetB2</em> classifier using both the original and the unbalanced dataset, and use the classification accuracy on the test set as the metric to compare different models. Train multiple models using different random seeds and calculate an average score for each.</p> <h4 id="data-augmentation">Data Augmentation</h4> <p>Build a conditional GAN model and train the generator to produce images of all 10 classes, conditioned on the class label as input. Use the generator to create images of the two minority classes. Using the <em>unbalanced</em> classifier mentioned above, pass these generated images through it, keeping only those that the model correctly classifies as belonging to the same class as the intended one (GAN input). Generate 500 new images for each class and build three new training sets from these:</p> <ul> <li><strong>augmented100</strong></li> <li><strong>augmented300</strong></li> <li><strong>augmented500</strong></li> </ul> <p>Each augments the unbalanced training set by 100, 300, and 500 images, respectively.</p> <h4 id="evaluation">Evaluation</h4> <p>Fine-tune multiple classifiers for each augmented dataset, calculate the group accuracy score, and compare it to the baseline. Additionally, calculate the per-class group accuracy for the minority classes across all trained classifiers and compare them.</p> <hr/> <h2 id="the-gan-rabbit-hole-Ô∏è">The GAN Rabbit Hole üï≥Ô∏è</h2> <p>So far, so good. I had my dataset, experiment design, and infrastructure (first time using Pulumi) set up. My unbalanced dataset was ready, and I had fine-tuned a classifier to establish a baseline. Time to generate some synthetic data!</p> <p>I started with <a href="https://keras.io/examples/generative/conditional_gan">this Keras example</a>, modifying it for image dimensions and channels (RGB). My first training run on the <em>unbalanced</em> dataset wasn‚Äôt good but produced exactly what I expected‚Äîblurry patches of green, brown, and blue, vaguely resembling satellite imagery.</p> <p><em>Great!</em> ‚Äì I thought ‚Äì <em>this is going in the right direction.</em> I tweaked hyperparameters systematically, adding a callback to generate samples every 10 epochs. After many trials, I still had little more than color-matched patches, maybe some crop-like structures‚Äîif I squinted. So, I explored deeper networks, different upsampling methods, and better class conditioning.</p> <p>That led me into researching more advanced GANs. I added an embedding layer for class labels, learned about projection discriminators <a href="https://arxiv.org/abs/1802.05637">(Miyato &amp; Koyama, 2018)</a>, and experimented with Wasserstein GANs with gradient penalty <a href="https://arxiv.org/abs/1704.00028">(WGAN-GP; Gulrajani et al., 2017)</a>. Each change meant longer training runs, but at least I never had to upgrade my instance üòÖ.</p> <p>Despite all the effort, nothing was working, my AWS bill was climbing, and I was running out of ideas. Then it hit me‚ÄîEuroSAT is a well-known dataset. Surely, someone had tried this before? Sure enough, I found <a href="https://www.cs.swarthmore.edu/~llwin1/files/labelled_sat_images_dcgan_lwin.pdf">a paper</a> from (probably) 2022 Swarthmore students who had used a similar model. I replicated their setup and‚Ä¶ nothing!</p> <p>But this was the turning point. I had proof that it <em>was</em> possible, just not with my dataset. So, I finally did what I should‚Äôve done earlier: trained a GAN on the <em>full</em> dataset. First try‚Ä¶ <strong>it worked!</strong></p> <h4 id="the-end-of-my-gan-learning-journey">The End of My GAN Learning Journey</h4> <p>The issue was the dataset imbalance all along. I had tried class weights but never focused on balancing techniques like oversampling.</p> <p>At this point, I decided to use the GAN trained on the full dataset. Sure, it weakened the project‚Äôs real-world applicability‚Äîthe whole goal was to handle imbalance with synthetic data‚Äîbut solving that problem was an entirely new project. The right call was to finish answering my original question and leave that challenge for another day.</p> <p>On the bright side, I learned so much about GANs, conditioning them and stabilizing training, so no regrets!</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2025-02-23-cgan-class/generated_highway-480.webp 480w,/assets/img/blog/2025-02-23-cgan-class/generated_highway-800.webp 800w,/assets/img/blog/2025-02-23-cgan-class/generated_highway-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/2025-02-23-cgan-class/generated_highway.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Generated samples of the <i>Highway</i> class. </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2025-02-23-cgan-class/generated_river-480.webp 480w,/assets/img/blog/2025-02-23-cgan-class/generated_river-800.webp 800w,/assets/img/blog/2025-02-23-cgan-class/generated_river-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/2025-02-23-cgan-class/generated_river.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Generated samples of the <i>River</i> class. </div> <hr/> <h2 id="final-results">Final Results</h2> <p>At this point, I had spent way more time (and money on AWS) than I had planned. For this reason I decided to adapt my analysis: I would train only 3 classifiers per setup. The issue was that this wouldn‚Äôt be near enough samples for calculating proper group statistics, so I ended up pulling out a trick.</p> <h4 id="estimating-variance-with-pooling">Estimating Variance with Pooling</h4> <p>Let \(x^i_j\) be the accuracy score of the \(j\)-th trained classifier (\(j \in [1,3]\)) for dataset \(i \in G\), where \(G\) is the set of datasets (or groups) mentioned above. I‚Äôll also add to \(G\) a variant that fine-tunes the classifier on the <em>unbalanced</em> dataset with class weights to compensate for imbalance.</p> <p>Let‚Äôs make two assumptions:</p> <ul> <li>Three samples are enough to estimate the mean of each group (outrageous, I know).</li> <li>All groups share the same (symetric) accuracy score distribution, just shifted by their mean.</li> </ul> <p>With this, we can subtract the group‚Äôs mean accuracy \(\mu^i\) from each sample, obtaining \(\tilde{x}^i_j = x^i_j - \mu^i\). By doing so, we‚Äôve effectively centered all distributions around zero. Since we assumed they were the same distribution but shifted, we can now ‚Äúborrow power‚Äù from the other samples and calculate a shared variance as:</p> \[\sigma^2 = \frac{1}{2|G|}\sum_{i\in G}\sum_{j=1}^{3}(\tilde{x}^i_j)^2\] <p>This is of course a simplification, it is meant to help visualize differences in the mean results and not to rigorously account for all sources of uncertainty.</p> <h4 id="performance-on-the-test-set">Performance on the Test Set</h4> <p>Finally! Do these generated images improve the classifier‚Äôs accuracy on the test set? Well, they do seem to help, but not more than simply training on the unbalanced dataset while giving more weight to the minority classes. But that result alone is a bit misleading. What caught me off guard was that when looking at the mean accuracy on the minority classes only, adding synthetic images actually performs worse.</p> <p>This result might seem strange at first‚Äîit certainly did to me‚Äîbut after thinking it through, I have a hypothesis. I suspect that, on the one hand, the generated samples lack variability and fail to capture all the details of the real data. On the other hand, they still upsample the minority classes. The effect is that the more synthetic images in the dataset, the more the model overfits on them, reducing per-class accuracy for these classes while smoothing out the decision boundaries for the majority classes, improving their accuracy. The net effect is positive, which is why the overall accuracy improves.</p> <p>If this hypothesis is correct‚Äîand considering that I trained the GAN on the full dataset‚Äîit suggests that effectively modeling the synthetic data is critical for dataset augmentation to work this way. Proving this hypothesis, though, is a whole project in itself, so I won‚Äôt attempt it today.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2025-02-23-cgan-class/test_set_performance-480.webp 480w,/assets/img/blog/2025-02-23-cgan-class/test_set_performance-800.webp 800w,/assets/img/blog/2025-02-23-cgan-class/test_set_performance-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/2025-02-23-cgan-class/test_set_performance.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2025-02-23-cgan-class/per_class_performance-480.webp 480w,/assets/img/blog/2025-02-23-cgan-class/per_class_performance-800.webp 800w,/assets/img/blog/2025-02-23-cgan-class/per_class_performance-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/2025-02-23-cgan-class/per_class_performance.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Mean classification accuracy on the full test set (left) and only considering the minority classes <i>Highway</i> and <i>River</i> (right) for after fine-tuning on each dataset labeled in the x-axis. </div> <h4 id="conclusion">Conclusion</h4> <p>This project started as a straightforward experiment in data augmentation but quickly turned into a deep dive into GANs, dataset balancing, and the unexpected ways synthetic data interacts with model training. While the generated images did improve overall accuracy, they didn‚Äôt outperform a simpler approach like class weighting‚Äîand, in fact, they hurt performance on the minority classes. That was an unexpected twist, but one that makes sense in hindsight: more data isn‚Äôt always better if it doesn‚Äôt capture the full complexity of the real thing.</p> <p>There are plenty of open questions left‚Äîlike whether a better GAN model, or perhaps a difussion model, trained directly on the unbalanced dataset could have made a difference. That‚Äôs a problem for another day. For now, this was a fun (if occasionally frustrating) exploration, and I‚Äôve learned a lot along the way. And at the very least, I now have a much better understanding of why dataset augmentation is trickier than it seems.</p>]]></content><author><name></name></author><category term="GAN"/><category term="image-classification"/><category term="deep-learning"/><category term="keras"/><summary type="html"><![CDATA[Balancing an image classification dataset using synthetic images]]></summary></entry><entry><title type="html">Test-Time Compute: My Take on Story Generation</title><link href="https://ssalb.github.io/blog/2025/test-time-compute-story-generation/" rel="alternate" type="text/html" title="Test-Time Compute: My Take on Story Generation"/><published>2025-01-07T09:00:00+00:00</published><updated>2025-01-07T09:00:00+00:00</updated><id>https://ssalb.github.io/blog/2025/test-time-compute-story-generation</id><content type="html" xml:base="https://ssalb.github.io/blog/2025/test-time-compute-story-generation/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2025-01-07-story-gen/tree_diagram.webp" sizes="95vw"/> <img src="/assets/img/blog/2025-01-07-story-gen/tree_diagram.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>We‚Äôve seen incredible progress in large language models (LLMs) over the past few years, driven largely by scaling up model sizes and training data. But as noted in a <a href="https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute">recent blog post by Hugging Face</a>, we‚Äôre starting to hit some hard limits‚Äîtraining these massive models requires billion-dollar compute clusters, and we‚Äôre also running out of high-quality training data.</p> <p>Enter test-time compute: instead of building ever-larger models, what if we let smaller models ‚Äúthink longer‚Äù about hard problems? Recent research shows this approach can be remarkably effective. In a <a href="https://arxiv.org/pdf/2408.03314">paper by Google DeepMind</a> published last August, the team demonstrates that with smart test-time compute allocation, smaller models can actually outperform models 14 times their size on certain tasks. Probably the most famous examples are OpenAI‚Äôs o1 and o3 models, but they‚Äôre not the only ones that can do these tricks: Deep Mind‚Äôs results were also replicated by the Hugging Face team as described in the blog post mentioned above.</p> <p>I wanted to get more familiar with these concepts, so I decided to explore them with a simple and fun toy project: story generation. Could test-time computing help a modest LLM write better stories by carefully evaluating and refining its outputs?</p> <p>Well‚Ä¶ yes! at least compared to the base model output. I have a demo under <a href="https://huggingface.co/spaces/ssalb/story_generator">this space</a>. It‚Äôll be live for a few days, but feel free to clone it later and run it yourself. The source code is also available in <a href="https://github.com/ssalb/story-beam-search">this GitHub repo</a>.</p> <hr/> <h2 id="the-building-blocks-beam-search-and-quality-metrics">The Building Blocks: Beam Search and Quality Metrics</h2> <p>My approach uses beam search, a method that explores multiple possible story variations simultaneously instead of generating just one. Think of it like a chess player considering different moves before committing to one. Concretely, it does this by expanding each partial story with a number of possible next paths (beams) and scoring them; it then keeps only the top-scoring beams (the beam width) and moves on to repeat this process for a determined number of steps. This way, the model stays focused on the most promising story paths while still branching out enough to discover interesting possibilities. But I needed a way for the system to judge which stories were ‚Äúbetter,‚Äù so I implemented three quality metrics:</p> <ul> <li><strong>Coherence</strong>: Do sentences flow naturally from one to the next? I evaluate this using cosine similarity between adjacent sentences.</li> <li><strong>Fluency</strong>: Does the text read smoothly and naturally? To approximate this, I used BERT to evaluate the probability of each generated token based on the previous tokens (by masking them). (Disclaimer: I really wanted to give <a href="https://huggingface.co/answerdotai/ModernBERT-base">ModernBERT</a> a try, so this biased my approach significantly. üòâ)</li> <li><strong>Genre alignment</strong>: Does the story match its intended genre? I used a zero-shot classifier to predict whether a piece of text could be labeled by a predefined genre.</li> </ul> <p>Writing a functional app took about 10% of the time at most, and the CI pipeline to get it running on a Hugging Face space another 10%. In contrast, about 40% of the time I invested was spent experimenting with these scoring algorithms. I tried different normalizations and ways of splitting the stories. For fluency, for example, I use the whole story as one unit. For genre alignment, I found it worked better by splitting stories into sentences and classifying them independently‚Äîthis helped control alignment throughout the story.</p> <p>Fun fact: the genre alignment scorer turned out to be a decently good, low-effort prompt injection mechanism. I check the probability of the initial prompt being classified as ‚Äústory‚Äù versus ‚Äúprompt injection.‚Äù If the ‚Äústoryness‚Äù is too low or the ‚Äúprompt injection‚Äù probability too high, I stop the process before generating anything. It‚Äôs by no means perfect, and I‚Äôve definitely seen a few false positives, but it‚Äôs surprisingly effective for a quick demo.</p> <h2 id="making-beam-search-work-for-creative-tasks">Making Beam Search Work for Creative Tasks</h2> <p>One interesting challenge emerged: basic beam search seems great at finding the ‚Äúoptimal‚Äù solution but not so great at generating diverse, creative outputs‚Äîmy first attempts returned stories that were way too similar, sometimes differing by only a single word. Taking inspiration from the <a href="https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute">blog post</a> mentioned earlier (see the DVTS section), I modified the algorithm to maintain independent ‚Äúbeams‚Äù of stories that develop separately, rather than constantly comparing and filtering them all together. This helped preserve more variety in the outputs.</p> <h2 id="the-computing-challenge">The Computing Challenge</h2> <p>Were you wondering where I spent the other 40% of my time? Well, here‚Äôs where it gets interesting: while generating a single story from a language model takes just a couple of seconds on a GPU (I tested on a T4), the full test-time computation process is much more intensive. With a modest-sized (and not particularly impressive anymore) model like GPT2, the entire process takes 3‚Äì5 minutes. Scale up to Llama 3.2 1B (my original target model) and you‚Äôll get significantly better stories, but you‚Äôll also be looking at 30+ minutes of processing time! That‚Äôs why I scaled it down for my demo.</p> <p>I‚Äôm sure my code can be optimized further, but even after some thorough refactoring to process data in batches wherever possible, I only improved runtime by about 20%. The iterative steps just take a while‚Äîat least compared to what we‚Äôre used to when using LLMs directly. I believe researchers are putting effort into embedding these search algorithms in the network architectures themselves, but I‚Äôm not an expert in this field, so don‚Äôt quote me on that!</p> <hr/> <h2 id="what-i-learned">What I Learned</h2> <p>Test-time computing offers a fascinating alternative to the ‚Äúbigger is better‚Äù mindset that often dominates LLM and AI development. While it does introduce significant computational overhead, it enables smaller models to produce higher-quality outputs through careful evaluation and refinement. Imagine how ‚Äúsmall model, big compute‚Äù could also help with things like dialogue systems, or specialized domain tasks; anything really that would benefit from ‚Äúthinking longer and in steps‚Äù.</p> <p>Of course, we have to acknowledge the elephant in the room: more inference steps cost more time, so if you need super-quick responses, you might be better off with bigger models. In practice, it will probably be a combination of both‚Äìas we keep pushing the limits of model scaling, these methods for making smarter use of inference-time compute will likely become increasingly important‚Äîespecially if new algorithms and hardware optimizations can streamline the process.</p> <p>For story generation specifically, in this experiment beam search seems to be very effective at finding ‚Äúoptimal‚Äù stories according to our metrics‚Äîthough maintaining creativity and diversity requires some clever tweaks to the standard approach. Perhaps other methods that would preference exploration over exploitation would work better. I do have a soft spot for Monte Carlo methods, so I‚Äôll try to find another <del>excuse</del> project to use a MC tree search next.</p> <h3 id="takeaways">Takeaways</h3> <ul> <li><strong>Small Models, Big Thinking</strong>: With enough ‚Äúthinking time,‚Äù a modest LLM can punch above its weight class.</li> <li><strong>Balancing Creativity &amp; Optimality</strong>: Beam search seems to be better at finding an optimal solution. Other methods might preference exploration more.</li> <li><strong>Real-World Viability</strong>: Extra processing time isn‚Äôt always ideal, but for certain applications it can be worth the trade-off.</li> </ul> <p>Feel free to tinker with the code, clone the project, or adapt it for your own experiments. I‚Äôd love to hear about your successes, hiccups, and any wild new ideas you come up with!</p>]]></content><author><name></name></author><category term="transformers"/><category term="llms"/><category term="test-time-compute"/><category term="beam-search"/><summary type="html"><![CDATA[Exploring test-time compute and beam search with a story generator app]]></summary></entry><entry><title type="html">If your company is not doing ML, it (probably) won‚Äôt start any time soon either</title><link href="https://ssalb.github.io/blog/2024/company-no-ml/" rel="alternate" type="text/html" title="If your company is not doing ML, it (probably) won‚Äôt start any time soon either"/><published>2024-03-22T09:00:00+00:00</published><updated>2024-03-22T09:00:00+00:00</updated><id>https://ssalb.github.io/blog/2024/company-no-ml</id><content type="html" xml:base="https://ssalb.github.io/blog/2024/company-no-ml/"><![CDATA[<div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/2024-03-22-no-ml/cover-480.webp 480w,/assets/img/blog/2024-03-22-no-ml/cover-800.webp 800w,/assets/img/blog/2024-03-22-no-ml/cover-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/blog/2024-03-22-no-ml/cover.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Photo by Lucas Fonseca: https://www.pexels.com/photo/man-in-front-of-monitor-2239655/ </div> <p>A recurrent struggle among ML practitioners such as Data Scientists and ML Engineers is that, despite job descriptions and conversations during the interview process, after some time at their job they find themselves with the feeling of doing tons of different things except what they were most excited about - building some ML models.</p> <p>I‚Äôve been in that situation myself, and have heard it over and over again from friends, colleagues and students. The solution? <em>‚ÄúChange jobs!‚Äù</em> you might think, but the reality is that this is often not the best solution.</p> <p>In this article, I would like to share my point of view on why this is so common and use it to illustrate how you can make a better decision by having a wider perspective. And, if after all you still decide to go out there and find a new job (I‚Äôm not suggesting either option is right), this could help you identify good alternatives more easily.</p> <hr/> <h2 id="why-is-my-company-not-investing-more-in-ml">Why is my company not investing more in ML?</h2> <p>If you‚Äôre a professional with ML skills, you are most likely well aware of the potential machine learning has to revolutionize various industries. But have you noticed that not all companies are jumping on the bandwagon? In fact, many companies, perhaps yours, are not doing much machine learning despite having some Data Scientists in their lines.</p> <p>Some arguments I often hear are:</p> <ul> <li><em>‚ÄúWe don‚Äôt have the infrastructure for it.‚Äù</em></li> <li><em>‚ÄúThe quality of our data is insufficient.‚Äù</em></li> </ul> <p>But I would argue that it‚Äôs almost never related to the organization‚Äôs maturity or incompetence, because both of these problems are straightforward to fix.</p> <p>So why are some companies not adopting machine learning? The answer is simple: <strong>how companies make money is what drives their behavior.</strong></p> <p>Big Tech companies and machine learning startups do lots of machine learning because it impacts their revenue. That‚Äôs not always the case in other industries.</p> <p>If your company is not making money directly from machine learning, it‚Äôs unlikely they will invest in it significantly regardless of their original intentions. Even if they are aware of the potential benefits, the costs associated with implementing and maintaining machine learning systems may not justify the return on investment at first sight.</p> <hr/> <h2 id="what-can-you-do-about-it">What can you do about it?</h2> <p>If you‚Äôre an ML practitioner currently working at a company that‚Äôs not doing enough machine learning (or not at all), I would completely understand if you are feeling frustrated and asking yourself whether you should look for a new employer.</p> <p>Although in principle neither option is wrong (staying or leaving), I would strongly suggest that you don‚Äôt rush this decision. By analyzing companies under this lens just described above, it‚Äôs possible to conclude that if you blindly jump to another job, chances are you‚Äôll end up in the same situation.</p> <p>So what can you do about it? Here are some tips:</p> <h4 id="consider-the-opportunities">Consider the opportunities</h4> <p>If your company is not doing machine learning, that doesn‚Äôt necessarily mean there are no opportunities for you. It‚Äôs important to evaluate the potential for career development and decide whether the opportunities available are beneficial for your career goals long-term.</p> <p>Personally, working as a Data Scientist at companies whose business model was based on software is where I improved my software/data engineering skills the most, which have been incredibly useful. On the other hand, working at companies with other ‚Äúnon-tech‚Äù business models was when I gained tons of experience managing projects, budgets, stakeholders, and processes.</p> <h4 id="analyze-companies-under-this-lens">Analyze companies under this lens</h4> <p>Perhaps, after considering all opportunities currently available, you still decide the best you can do for your future is to look for a new challenge. In this case, understanding the business model of your potential employers can be incredibly useful for anticipating the kind of role you‚Äôll actually have, regardless of the job description. You can also use this point of view to formulate questions while interviewing for new jobs.</p> <hr/> <h2 id="final-thoughts">Final thoughts</h2> <p>In this article, I‚Äôve used this prism (<em>how does company X make money?</em>) to analyze why some companies are not where they said they want to be regarding ML development and implementation. But in fact, you can use the same lens to understand many other situations, such as:</p> <ul> <li>Which departments are likely to experience the biggest growth over time.</li> <li>Where you, as a Data professional, can have the largest impact with your work.</li> </ul> <p>By applying this mindset, you can make more informed career decisions and set yourself up for success in the long run.</p>]]></content><author><name></name></author><category term="career-development"/><category term="opinion"/><summary type="html"><![CDATA[Photo by Lucas Fonseca: https://www.pexels.com/photo/man-in-front-of-monitor-2239655/]]></summary></entry></feed>